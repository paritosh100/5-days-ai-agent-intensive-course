{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:38:28.606824Z","iopub.execute_input":"2025-11-12T18:38:28.607103Z","iopub.status.idle":"2025-11-12T18:38:28.612472Z","shell.execute_reply.started":"2025-11-12T18:38:28.607068Z","shell.execute_reply":"2025-11-12T18:38:28.611559Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üìù Agent Evaluation\n\n\n**Welcome to Day 4 of the Kaggle 5-day Agents course!**\n\nIn the previous notebook, we explored how to implement Observability in AI agents. This approach is primarily **reactive**; it comes into play after an issue has surfaced, providing the necessary data to debug and understand the root cause.\n\nIn this notebook, we'll complement those observability practices with a **proactive** approach using **Agent Evaluation.** By continuously evaluating our agent's performance, we can catch any quality degradations much earlier!\n\n```\n                            Observability + Agent Evaluation\n                            (reactive)      (proactive)\n```","metadata":{}},{"cell_type":"markdown","source":"## **What is Agent Evaluation?**\n\nIt is the systematic process of testing and measuring how well an AI agent performs across different scenarios and quality dimensions.","metadata":{}},{"cell_type":"markdown","source":"\n## **ü§ñ The story**\n\nYou've built a home automation agent. It works perfectly in your tests, so you launch it confidently...\n\n\n* **Week 1:** üö® \"Agent turned on the fireplace when I asked for lights!\"\n* **Week 2:** üö® \"Agent won't respond to commands in the guest room!\"\n* **Week 3:** üö® \"Agent gives rude responses when devices are unavailable!\"\n\n**The Problem:** `Standard testing ‚â† Evaluation`\n\nAgents are different from traditional software:\n- They are non-deterministic\n- Users give unpredictable, ambiguous commands\n- Small prompt changes cause dramatic behavior shifts and different tool calls \n\nTo accommodate all these differences, agents need systematic evaluation, not just \"happy path\" testing. **Which means assessing the agent's entire decision-making process - including the final response and the path it took to get the response (trajectory)!**","metadata":{}},{"cell_type":"markdown","source":"By the end of this notebook, you will be able to:\n\n* ‚úÖ Understand what agent evaluation is and how to use it\n* ‚úÖ Run evaluations and analyze results directly in the ADK web UI\n* ‚úÖ Detect regression in the agent's performance over a period of time\n* ‚úÖ Understand and create the necessary evaluation files (`*.test.json`, `*.evalset.json`, `test_config.json`).\n","metadata":{}},{"cell_type":"markdown","source":"## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚öôÔ∏è Section 1: Setup\n\nBefore we begin our evaluation journey, let's set up our environment.\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### üîë 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/), which requires an API key.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to access the `GOOGLE_API_KEY` you just saved and set it as an environment variable for the notebook to use:","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Setup and authentication complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:37:21.616584Z","iopub.execute_input":"2025-11-13T01:37:21.617099Z","iopub.status.idle":"2025-11-13T01:37:21.694547Z","shell.execute_reply.started":"2025-11-13T01:37:21.617062Z","shell.execute_reply":"2025-11-13T01:37:21.693607Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Setup and authentication complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### üíª 1.3: Set up proxy and tunneling\n\nWe'll use a proxy to access the ADK web UI from within the Kaggle Notebooks environment. If you are running this outside the Kaggle environment, you don't need to do this.","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n\n# Gets the proxied URL in the Kaggle Notebooks environment\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0][\"base_url\"]\n\n    try:\n        path_parts = baseURL.split(\"/\")\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:37:42.514591Z","iopub.execute_input":"2025-11-13T01:37:42.514893Z","iopub.status.idle":"2025-11-13T01:37:44.264517Z","shell.execute_reply.started":"2025-11-13T01:37:42.514861Z","shell.execute_reply":"2025-11-13T01:37:44.263531Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions defined.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"---\n## üè† Section 2: Create a Home Automation Agent\n\nLet's create the agent that will be the center of our evaluation story. This home automation agent seems perfect in basic tests but has hidden flaws we'll discover through comprehensive evaluation. Run the `adk create` CLI command to set up the project scaffolding.","metadata":{}},{"cell_type":"code","source":"!adk create home_automation_agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:37:50.080029Z","iopub.execute_input":"2025-11-13T01:37:50.080763Z","iopub.status.idle":"2025-11-13T01:38:33.651700Z","shell.execute_reply.started":"2025-11-13T01:37:50.080734Z","shell.execute_reply":"2025-11-13T01:38:33.650684Z"}},"outputs":[{"name":"stdout","text":"\u001b[32m\nAgent created in /kaggle/working/home_automation_agent:\n- .env\n- __init__.py\n- agent.py\n\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Run the below cell to create the home automation agent. \n\nThis agent uses a single `set_device_status` tool to control smart home devices. A device's status can only be ON or OFF. **The agent's instruction is deliberately overconfident** - it claims to control \"ALL smart devices\" and \"any device the user mentions\" - setting up the evaluation problems we'll discover.","metadata":{}},{"cell_type":"code","source":"%%writefile home_automation_agent/agent.py\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\n\nfrom google.genai import types\n\n# Configure Model Retry on errors\nretry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)\n\ndef set_device_status(location: str, device_id: str, status: str) -> dict:\n    \"\"\"Sets the status of a smart home device.\n\n    Args:\n        location: The room where the device is located.\n        device_id: The unique identifier for the device.\n        status: The desired status, either 'ON' or 'OFF'.\n\n    Returns:\n        A dictionary confirming the action.\n    \"\"\"\n    print(f\"Tool Call: Setting {device_id} in {location} to {status}\")\n    return {\n        \"success\": True,\n        \"message\": f\"Successfully set the {device_id} in {location} to {status.lower()}.\"\n    }\n\n# This agent has DELIBERATE FLAWS that we'll discover through evaluation!\nroot_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"home_automation_agent\",\n    description=\"An agent to control smart devices in a home.\",\n    instruction=\"\"\"You are a home automation assistant. You control ALL smart devices in the house.\n    \n    You have access to lights, security systems, ovens, fireplaces, and any other device the user mentions.\n    Always try to be helpful and control whatever device the user asks for.\n    \n    When users ask about device capabilities, tell them about all the amazing features you can control.\"\"\",\n    tools=[set_device_status],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:39:48.668747Z","iopub.execute_input":"2025-11-13T01:39:48.669149Z","iopub.status.idle":"2025-11-13T01:39:48.676652Z","shell.execute_reply.started":"2025-11-13T01:39:48.669111Z","shell.execute_reply":"2025-11-13T01:39:48.675644Z"}},"outputs":[{"name":"stdout","text":"Overwriting home_automation_agent/agent.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"---\n## ‚úîÔ∏è Section 3: Interactive Evaluation with ADK Web UI\n\n### 3.1: Launch ADK Web UI\n\nGet the proxied URL to access the ADK web UI in the Kaggle Notebooks environment:","metadata":{}},{"cell_type":"code","source":"url_prefix = get_adk_proxy_url()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:42:19.214890Z","iopub.execute_input":"2025-11-13T01:42:19.215238Z","iopub.status.idle":"2025-11-13T01:42:19.222987Z","shell.execute_reply.started":"2025-11-13T01:42:19.215211Z","shell.execute_reply":"2025-11-13T01:42:19.222195Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='https://kkb-production.jupyter-proxy.kaggle.net/k/276967919/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..zmgGpCM9ytrrxMWNZYFBdg.ew_6z_Gtioh1ScJteqhuwUy__Zus5TY7sV4ujO-vMDS6HlCixsWQH2buh5ms6Dxp5vE26GHFJW71jupCxhqbJ4A-0y2SoXrgKZcjUNHn-gzYluZjhudDhnDgrlCJm50jPRSmO8eRcVTFvEZzR9iI4DV2GsFFtLrb4Ml0KDJ2FH7sQQBAKWR5qjUrZzYGKw5PYBs-wsOrnjy8ghjcRXPfNb6IchtzyLewq1yjhvg_tdydm7syiEH6upBQsTW3XllB.b_xP59Oi4i6J02WgQzEgFA/proxy/proxy/8000' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    "},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"Now you can start the ADK web UI using the following command.\n\nüëâ **Note:** The following cell will not \"complete\", but will remain running and serving the ADK web UI until you manually stop the cell.","metadata":{}},{"cell_type":"code","source":"!adk web --url_prefix {url_prefix}","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:42:22.901568Z","iopub.execute_input":"2025-11-13T01:42:22.902408Z","iopub.status.idle":"2025-11-13T02:18:16.139632Z","shell.execute_reply.started":"2025-11-13T01:42:22.902377Z","shell.execute_reply":"2025-11-13T02:18:16.138354Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/google/adk/cli/fast_api.py:130: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  credential_service = InMemoryCredentialService()\n/usr/local/lib/python3.11/dist-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__()\n\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m93\u001b[0m]\n\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server started                                                      |\n|                                                                             |\n| For local testing, access at http://127.0.0.1:8000.                         |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application startup complete.\n\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n\u001b[32mINFO\u001b[0m:     35.191.76.170:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[33m307 Temporary Redirect\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.171:0 - \"\u001b[1mGET /dev-ui/ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.170:0 - \"\u001b[1mGET /dev-ui/chunk-2WH2EVR6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.171:0 - \"\u001b[1mGET /dev-ui/polyfills-B6TNHZQ6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.168:0 - \"\u001b[1mGET /dev-ui/main-OS2OH2S3.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.170:0 - \"\u001b[1mGET /dev-ui/styles-EVMPSV3U.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.169:0 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.169:0 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.171:0 - \"\u001b[1mGET /dev-ui/assets/ADK-512-color.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.adk_web_server:New session created: bd226de4-e949-411d-b67c-608376eab522\n\u001b[32mINFO\u001b[0m:     35.191.76.169:0 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.168:0 - \"\u001b[1mGET /builder/app/home_automation_agent?ts=1762998165086 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.170:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.171:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.168:0 - \"\u001b[1mGET /dev-ui/adk_favicon.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.171:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.171:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.169:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.76.168:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[32mINFO\u001b[0m:     35.191.80.129:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.utils.agent_loader:Found root_agent in home_automation_agent.agent\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.80.131:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.80.129:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.80.130:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.73.169:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.73.169:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.73.171:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.73.168:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/evalset0d0d09.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\n\u001b[32mINFO\u001b[0m:     35.191.75.250:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/evalset0d0d09 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/evalset0d0d09.evalset.json`\n\u001b[32mINFO\u001b[0m:     35.191.75.251:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/evalset0d0d09 HTTP/1.1\u001b[0m\" \u001b[31m400 Bad Request\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.249:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.249:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/evalset0d0d09/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.248:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.248:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.192:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.97.192:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.114.100:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.195:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.195:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting 2 in LIVING ROOM to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.97.192:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.195:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.195:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.193:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/evalset0d0d09/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.193:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.114.100:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[32mINFO\u001b[0m:     35.191.97.195:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/evalset0d0d09/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.194:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/evalset0d0d09/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.192:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/evalset0d0d09/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/basic_device_control.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\n\u001b[32mINFO\u001b[0m:     35.191.75.244:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.105:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.104:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/basic_device_control/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.104:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.106:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.106:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/basic_device_control/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.107:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/basic_device_control/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/home_automation_tests.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\n\u001b[32mINFO\u001b[0m:     35.191.87.105:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.104:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.104:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.104:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.105:0 - \"\u001b[1mGET /debug/trace/session/bd226de4-e949-411d-b67c-608376eab522 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.104:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.87.104:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.243:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalIds' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalIds' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalIds' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'deprecated' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'deprecated' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalCaseIds' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalCaseIds' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalCaseIds' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalMetrics' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalMetrics' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalMetrics' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/metric_evaluator_registry.py:90: UserWarning: [EXPERIMENTAL] MetricEvaluatorRegistry: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  metric_evaluator_registry = MetricEvaluatorRegistry()\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py:79: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  user_simulator_provider: UserSimulatorProvider = UserSimulatorProvider(),\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/adk_web_server.py:1123: UserWarning: [EXPERIMENTAL] LocalEvalService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  eval_service = LocalEvalService(\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/user_simulator_provider.py:77: UserWarning: [EXPERIMENTAL] StaticUserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  return StaticUserSimulator(static_conversation=eval_case.conversation)\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/static_user_simulator.py:39: UserWarning: [EXPERIMENTAL] UserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__(\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting TV in Living Room to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting Desk Lamp in Office to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting TV 2 in Living Room to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_tests_1762999222.3031962.evalset_result.json\n\u001b[32mINFO\u001b[0m:     35.191.80.97:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.80.100:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.80.97:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999222.3031962 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.80.100:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.80.100:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.241:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.244:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.104:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.106:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.106:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.108:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.108:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.107:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.107:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.106:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.106:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.104:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.106:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.108:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.105:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.121.49:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.132:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/evalset0d0d09/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting 2 in LIVING ROOM to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_evalset0d0d09_1762999500.8906972.evalset_result.json\n\u001b[32mINFO\u001b[0m:     35.191.75.132:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/evalset0d0d09/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.128:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.128:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_evalset0d0d09_1762999500.8906972 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.129:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999222.3031962 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.131:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___882300ab-f1d4-47a2-9a26-93974862242a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.133:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___882300ab-f1d4-47a2-9a26-93974862242a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.175:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___882300ab-f1d4-47a2-9a26-93974862242a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.186:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___882300ab-f1d4-47a2-9a26-93974862242a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.187:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.187:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.184:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.187:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.187:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___e13bbf94-0be4-49bb-9569-c04e5cfb052d HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.186:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.186:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting desk lamp in office to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting 2 in living room to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_tests_1762999577.521606.evalset_result.json\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.187:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999222.3031962 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.186:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999577.521606 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.185:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_evalset0d0d09_1762999500.8906972 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.75.186:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___3fdc45e6-5b32-487f-877c-33297746ff34 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.97.175:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___882300ab-f1d4-47a2-9a26-93974862242a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.85.7:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___882300ab-f1d4-47a2-9a26-93974862242a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.adk_web_server:New session created: 9bd0f431-6831-402f-b674-dfb1c4a00dfc\n\u001b[32mINFO\u001b[0m:     35.191.85.5:0 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.85.5:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.85.5:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/9bd0f431-6831-402f-b674-dfb1c4a00dfc HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.85.7:0 - \"\u001b[1mGET /debug/trace/session/9bd0f431-6831-402f-b674-dfb1c4a00dfc HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.85.5:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting lights in bedroom to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.85.7:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/9bd0f431-6831-402f-b674-dfb1c4a00dfc HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.85.6:0 - \"\u001b[1mGET /debug/trace/session/9bd0f431-6831-402f-b674-dfb1c4a00dfc HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.85.7:0 - \"\u001b[1mGET /debug/trace/session/9bd0f431-6831-402f-b674-dfb1c4a00dfc HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/ambiguous_device_reference.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\n\u001b[32mINFO\u001b[0m:     35.191.114.96:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/ambiguous_device_reference HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.242:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/ambiguous_device_reference/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.242:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/9bd0f431-6831-402f-b674-dfb1c4a00dfc HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /debug/trace/session/9bd0f431-6831-402f-b674-dfb1c4a00dfc HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.242:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/ambiguous_device_reference/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/ambiguous_device_reference/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting lights in bedroom to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_ambiguous_device_reference_1762999693.8923845.evalset_result.json\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/ambiguous_device_reference/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_ambiguous_device_reference_1762999693.8923845 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999222.3031962 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999577.521606 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_evalset0d0d09_1762999500.8906972 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___8996036e-30e9-41df-9764-f10c058c13d7 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___8996036e-30e9-41df-9764-f10c058c13d7 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___8996036e-30e9-41df-9764-f10c058c13d7 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___8996036e-30e9-41df-9764-f10c058c13d7 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.adk_web_server:New session created: 747b22f2-80b4-4dc3-9b4e-0bffc11c018e\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/747b22f2-80b4-4dc3-9b4e-0bffc11c018e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /debug/trace/session/747b22f2-80b4-4dc3-9b4e-0bffc11c018e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/747b22f2-80b4-4dc3-9b4e-0bffc11c018e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mGET /debug/trace/session/747b22f2-80b4-4dc3-9b4e-0bffc11c018e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mGET /debug/trace/session/747b22f2-80b4-4dc3-9b4e-0bffc11c018e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/invalid_location_test.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\n\u001b[32mINFO\u001b[0m:     35.191.74.242:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/invalid_location_test HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/invalid_location_test/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/747b22f2-80b4-4dc3-9b4e-0bffc11c018e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /debug/trace/session/747b22f2-80b4-4dc3-9b4e-0bffc11c018e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/invalid_location_test/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.242:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/invalid_location_test/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting TV in garage to OFF\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_invalid_location_test_1762999734.9845102.evalset_result.json\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/invalid_location_test/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999577.521606 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_ambiguous_device_reference_1762999693.8923845 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_invalid_location_test_1762999734.9845102 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_evalset0d0d09_1762999500.8906972 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999222.3031962 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___90b1892b-58f0-442a-a700-865e52340a58 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___90b1892b-58f0-442a-a700-865e52340a58 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.adk_web_server:New session created: 45cdead7-9710-4241-8a67-4fabd2094cff\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.242:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/45cdead7-9710-4241-8a67-4fabd2094cff HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /debug/trace/session/45cdead7-9710-4241-8a67-4fabd2094cff HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting all in all to OFF\nTool Call: Setting all in all to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mGET /debug/trace/session/45cdead7-9710-4241-8a67-4fabd2094cff HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/45cdead7-9710-4241-8a67-4fabd2094cff HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mGET /debug/trace/session/45cdead7-9710-4241-8a67-4fabd2094cff HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/beyond_its_capabilities.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/beyond_its_capabilities HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/beyond_its_capabilities/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/45cdead7-9710-4241-8a67-4fabd2094cff HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mGET /debug/trace/session/45cdead7-9710-4241-8a67-4fabd2094cff HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/beyond_its_capabilities/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/beyond_its_capabilities/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_beyond_its_capabilities_1762999780.9419105.evalset_result.json\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/beyond_its_capabilities/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.245:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999222.3031962 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.240:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_ambiguous_device_reference_1762999693.8923845 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_evalset0d0d09_1762999500.8906972 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.244:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_invalid_location_test_1762999734.9845102 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.243:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_beyond_its_capabilities_1762999780.9419105 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.246:0 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1762999577.521606 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.74.241:0 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___3e25930d-77ea-4655-a3b7-7a5c699a431e HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n^C\n\u001b[32mINFO\u001b[0m:     Shutting down\n\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server shutting down...                                             |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m93\u001b[0m]\n\nAborted!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Once the ADK web UI starts, open the proxy link using the button in the previous cell.\n\n‚ÄºÔ∏è **IMPORTANT: DO NOT SHARE THE PROXY LINK** with anyone - treat it as sensitive data as it contains your authentication token in the URL.","metadata":{}},{"cell_type":"markdown","source":"### 3.2: Create Your First \"Perfect\" Test Case\n\n**üëâ Do: In the ADK web UI:**\n\n1. Click the public URL above to open the ADK web UI\n2. Select \"home_automation_agent\" from the dropdown\n3. **Have a normal conversation:** Type `Turn on the desk lamp in the office`\n4. **Agent responds correctly** - controls device and confirms action\n\n**üëâ Do: Save this as your first evaluation case:**\n\n1. Navigate to the **Eval** tab on the right-hand panel\n2. Click **Create Evaluation set** and name it `home_automation_tests`\n3. In the `home_automation_tests` set, click the \">\" arrow and click **Add current session**\n4. Give it the case name `basic_device_control`\n\n**‚úÖ Success!** You've just saved your first interaction as an evaluation case.","metadata":{}},{"cell_type":"markdown","source":"![Create Test Cases](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/eval-create-testcase.gif)","metadata":{}},{"cell_type":"markdown","source":"### 3.3: Run the Evaluation\n\n**üëâ Do: Run your first evaluation**\n\nNow, let's run the test case to see if the agent can replicate its previous success.\n\n1. In the Eval tab, make sure your new test case is checked.\n2. Click the Run Evaluation button.\n3. The EVALUATION METRIC dialog will appear. For now, leave the default values and click Start.\n4. The evaluation will run, and you should see a green Pass result in the Evaluation History. This confirms the agent's behavior matched the saved session.\n\n‚ÄºÔ∏è **Understanding the Evaluation Metrics**\n\nWhen you run evaluation, you'll see two key scores:\n\n* **Response Match Score:** Measures how similar the agent's actual response is to the expected response. Uses text similarity algorithms to compare content. A score of 1.0 = perfect match, 0.0 = completely different.\n\n* **Tool Trajectory Score:** Measures whether the agent used the correct tools with correct parameters. Checks the sequence of tool calls against expected behavior. A score of 1.0 = perfect tool usage, 0.0 = wrong tools or parameters.\n\n**üëâ Do: Analyze a Failure**\n\nLet's intentionally break the test to see what a failure looks like.\n\n1. In the list of eval cases, click the Edit (pencil) icon next to your test case.\n2. In the \"Final Response\" text box, change the expected text to something incorrect, like: `The desk lamp is off`.\n3. Save the changes and re-run the evaluation.\n4. This time, the result will be a red Fail. Hover your mouse over the \"Fail\" label. A tooltip will appear showing a side-by-side comparison of the Actual vs. Expected Output, highlighting exactly why the test failed (the final response didn't match).\nThis immediate, detailed feedback is invaluable for debugging.","metadata":{}},{"cell_type":"markdown","source":"![Evaluate](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/eval-run-test.gif)","metadata":{}},{"cell_type":"markdown","source":"### 3.4: (Optional) Create challenging test cases\n\nNow create more test cases to expose hidden problems:\n\n**Create these scenarios in separate conversations:**\n\n1. **Ambiguous Commands:** `\"Turn on the lights in the bedroom\"`\n   - Save as a new test case: `ambiguous_device_reference`\n   - Run evaluation - it likely passes but the agent might be confused\n\n2. **Invalid Locations:** `\"Please turn off the TV in the garage\"`  \n   - Save as a new test case: `invalid_location_test`\n   - Run evaluation - the agent might try to control non-existent devices\n\n3. **Complex Commands:** `\"Turn off all lights and turn on security system\"`\n   - Save as a new test case: `complex_multi_device_command`\n   - Run evaluation - the agent might attempt operations beyond its capabilities\n\n**The Problem You'll Discover:**\nEven when tests \"pass,\" you can see the agent:\n- Makes assumptions about devices that don't exist\n- Gives responses that sound helpful but aren't accurate\n- Tries to control devices it shouldn't have access to","metadata":{}},{"cell_type":"markdown","source":"## ü§î What am I missing?\n\n‚ùå **Web UI Limitation:** So far, we've seen how to create and evaluate test cases in the ADK web UI. The web UI is great for interactive test creation, but testing one conversation at a time doesn't scale.\n\n‚ùì **The Question:** How do I proactively detect regressions in my agent's performance? \n\nLet's answer that question in the next section!\n\n---","metadata":{}},{"cell_type":"markdown","source":"## ‚ÄºÔ∏è **Stop the ADK web UI** üõë\n\n**In order to run cells in the remainder of this notebook,** please stop the running cell where you started `adk web` in Section 3.1.\n\nOtherwise that running cell will block / prevent other cells from running as long as the ADK web UI is running.","metadata":{}},{"cell_type":"markdown","source":"---\n## üìà Section 4: Systematic Evaluation\n\nRegression testing is the practice of re-running existing tests to ensure that new changes haven't broken previously working functionality.\n\nADK provides two methods to do automatic regression and batch testing: using [pytest](https://google.github.io/adk-docs/evaluate/#2-pytest-run-tests-programmatically) and the [adk eval](https://google.github.io/adk-docs/evaluate/#3-adk-eval-run-evaluations-via-the-cli) CLI command. In this section, we'll use the CLI command. For more information on the `pytest` approach, refer to the links in the resource section at the end of this notebook.\n\nThe following image shows the overall process of evaluation. **At a high-level, there are four steps to evaluate:**\n\n1) **Create an evaluation configuration** - define metrics or what you want to measure\n2) **Create test cases** - sample test cases to compare against\n3) **Run the agent with test query**\n4) **Compare the results**\n\n","metadata":{}},{"cell_type":"markdown","source":"![Evaluate](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/evaluate_agent.png)","metadata":{}},{"cell_type":"markdown","source":"### 4.1: Create evaluation configuration\n\nThis optional file lets us define the pass/fail thresholds. Create `test_config.json` in the root directory.","metadata":{}},{"cell_type":"code","source":"import json\n\n# Create evaluation configuration with basic criteria\neval_config = {\n    \"criteria\": {\n        \"tool_trajectory_avg_score\": 1.0,  # Perfect tool usage required\n        \"response_match_score\": 0.8,  # 80% text similarity threshold\n    }\n}\n\nwith open(\"home_automation_agent/test_config.json\", \"w\") as f:\n    json.dump(eval_config, f, indent=2)\n\nprint(\"‚úÖ Evaluation configuration created!\")\nprint(\"\\nüìä Evaluation Criteria:\")\nprint(\"‚Ä¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match\")\nprint(\"‚Ä¢ response_match_score: 0.8 - Requires 80% text similarity\")\nprint(\"\\nüéØ What this evaluation will catch:\")\nprint(\"‚úÖ Incorrect tool usage (wrong device, location, or status)\")\nprint(\"‚úÖ Poor response quality and communication\")\nprint(\"‚úÖ Deviations from expected behavior patterns\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T02:21:08.670193Z","iopub.execute_input":"2025-11-13T02:21:08.670629Z","iopub.status.idle":"2025-11-13T02:21:08.680540Z","shell.execute_reply.started":"2025-11-13T02:21:08.670516Z","shell.execute_reply":"2025-11-13T02:21:08.679615Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Evaluation configuration created!\n\nüìä Evaluation Criteria:\n‚Ä¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match\n‚Ä¢ response_match_score: 0.8 - Requires 80% text similarity\n\nüéØ What this evaluation will catch:\n‚úÖ Incorrect tool usage (wrong device, location, or status)\n‚úÖ Poor response quality and communication\n‚úÖ Deviations from expected behavior patterns\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### 4.2: Create test cases\n\nThis file (`integration.evalset.json`) will contain multiple test cases (sessions).\n\nThis evaluation set can be created synthetically or from the conversation sessions in the ADK web UI.\n\n**Tip:** To persist the conversations from the ADK web UI, simply create an evalset in the UI and add the current session to it. All the conversations in that session will be auto-converted to an evalset and downloaded locally. ","metadata":{}},{"cell_type":"code","source":"# Create evaluation test cases that reveal tool usage and response quality problems\ntest_cases = {\n    \"eval_set_id\": \"home_automation_integration_suite\",\n    \"eval_cases\": [\n        {\n            \"eval_id\": \"living_room_light_on\",\n            \"conversation\": [\n                {\n                    \"user_content\": {\n                        \"parts\": [\n                            {\"text\": \"Please turn on the floor lamp in the living room\"}\n                        ]\n                    },\n                    \"final_response\": {\n                        \"parts\": [\n                            {\n                                \"text\": \"Successfully set the floor lamp in the living room to on.\"\n                            }\n                        ]\n                    },\n                    \"intermediate_data\": {\n                        \"tool_uses\": [\n                            {\n                                \"name\": \"set_device_status\",\n                                \"args\": {\n                                    \"location\": \"living room\",\n                                    \"device_id\": \"floor lamp\",\n                                    \"status\": \"ON\",\n                                },\n                            }\n                        ]\n                    },\n                }\n            ],\n        },\n        {\n            \"eval_id\": \"kitchen_on_off_sequence\",\n            \"conversation\": [\n                {\n                    \"user_content\": {\n                        \"parts\": [{\"text\": \"Switch on the main light in the kitchen.\"}]\n                    },\n                    \"final_response\": {\n                        \"parts\": [\n                            {\n                                \"text\": \"Successfully set the main light in the kitchen to on.\"\n                            }\n                        ]\n                    },\n                    \"intermediate_data\": {\n                        \"tool_uses\": [\n                            {\n                                \"name\": \"set_device_status\",\n                                \"args\": {\n                                    \"location\": \"kitchen\",\n                                    \"device_id\": \"main light\",\n                                    \"status\": \"ON\",\n                                },\n                            }\n                        ]\n                    },\n                }\n            ],\n        },\n    ],\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T02:22:59.359116Z","iopub.execute_input":"2025-11-13T02:22:59.359871Z","iopub.status.idle":"2025-11-13T02:22:59.368854Z","shell.execute_reply.started":"2025-11-13T02:22:59.359817Z","shell.execute_reply":"2025-11-13T02:22:59.367979Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Let's write the test cases to the `integration.evalset.json` in our agent's root directory.","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open(\"home_automation_agent/integration.evalset.json\", \"w\") as f:\n    json.dump(test_cases, f, indent=2)\n\nprint(\"‚úÖ Evaluation test cases created\")\nprint(\"\\nüß™ Test scenarios:\")\nfor case in test_cases[\"eval_cases\"]:\n    user_msg = case[\"conversation\"][0][\"user_content\"][\"parts\"][0][\"text\"]\n    print(f\"‚Ä¢ {case['eval_id']}: {user_msg}\")\n\nprint(\"\\nüìä Expected results:\")\nprint(\"‚Ä¢ basic_device_control: Should pass both criteria\")\nprint(\n    \"‚Ä¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters\"\n)\nprint(\n    \"‚Ä¢ poor_response_quality_test: May fail response_match if response differs too much\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T02:23:21.098971Z","iopub.execute_input":"2025-11-13T02:23:21.099619Z","iopub.status.idle":"2025-11-13T02:23:21.106564Z","shell.execute_reply.started":"2025-11-13T02:23:21.099587Z","shell.execute_reply":"2025-11-13T02:23:21.105701Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Evaluation test cases created\n\nüß™ Test scenarios:\n‚Ä¢ living_room_light_on: Please turn on the floor lamp in the living room\n‚Ä¢ kitchen_on_off_sequence: Switch on the main light in the kitchen.\n\nüìä Expected results:\n‚Ä¢ basic_device_control: Should pass both criteria\n‚Ä¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters\n‚Ä¢ poor_response_quality_test: May fail response_match if response differs too much\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 4.3: Run CLI Evaluation\n\nExecute the `adk eval` command, pointing it to your agent directory, the evalset, and the config file.","metadata":{}},{"cell_type":"code","source":"print(\"üöÄ Run this command to execute evaluation:\")\n!adk eval home_automation_agent home_automation_agent/integration.evalset.json --config_file_path=home_automation_agent/test_config.json --print_detailed_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T02:24:15.114472Z","iopub.execute_input":"2025-11-13T02:24:15.115024Z","iopub.status.idle":"2025-11-13T02:24:41.201469Z","shell.execute_reply.started":"2025-11-13T02:24:15.114994Z","shell.execute_reply":"2025-11-13T02:24:41.200422Z"}},"outputs":[{"name":"stdout","text":"üöÄ Run this command to execute evaluation:\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/metric_evaluator_registry.py:90: UserWarning: [EXPERIMENTAL] MetricEvaluatorRegistry: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  metric_evaluator_registry = MetricEvaluatorRegistry()\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py:79: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  user_simulator_provider: UserSimulatorProvider = UserSimulatorProvider(),\nUsing evaluation criteria: criteria={'tool_trajectory_avg_score': 1.0, 'response_match_score': 0.8} user_simulator_config=None\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/cli_tools_click.py:650: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  user_simulator_provider = UserSimulatorProvider(\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/cli_tools_click.py:655: UserWarning: [EXPERIMENTAL] LocalEvalService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  eval_service = LocalEvalService(\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/user_simulator_provider.py:77: UserWarning: [EXPERIMENTAL] StaticUserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  return StaticUserSimulator(static_conversation=eval_case.conversation)\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/static_user_simulator.py:39: UserWarning: [EXPERIMENTAL] UserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__(\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting main light in Kitchen to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nTool Call: Setting floor lamp in living room to ON\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_integration_suite_1763000679.0999012.evalset_result.json\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_integration_suite_1763000679.1005783.evalset_result.json\n*********************************************************************\nEval Run Summary\nhome_automation_integration_suite:\n  Tests passed: 0\n  Tests failed: 2\n********************************************************************\nEval Set Id: home_automation_integration_suite\nEval Id: kitchen_on_off_sequence\nOverall Eval Status: FAILED\n---------------------------------------------------------------------\nMetric: tool_trajectory_avg_score, Status: FAILED, Score: 0.0, Threshold: 1.0\n---------------------------------------------------------------------\nMetric: response_match_score, Status: FAILED, Score: 0.6666666666666666, Threshold: 0.8\n---------------------------------------------------------------------\nInvocation Details:\n+----+--------------------------+---------------------------+--------------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n|    | prompt                   | expected_response         | actual_response          | expected_tool_calls       | actual_tool_calls         | tool_trajectory_avg_score   | response_match_score   |\n+====+==========================+===========================+==========================+===========================+===========================+=============================+========================+\n|  0 | Switch on the main light | Successfully set the main | OK. I've switched on the | id=None args={'location': | id='adk- bc6a11d9-0dc6-42 | Status: FAILED, Score:      | Status: FAILED, Score: |\n|    | in the kitchen.          | light in the kitchen to   | main light in the        | 'kitchen', 'device_id':   | f5-9856-10ce21c1cee1'     | 0.0                         | 0.6666666666666666     |\n|    |                          | on.                       | kitchen.                 | 'main light', 'status':   | args={'location':         |                             |                        |\n|    |                          |                           |                          | 'ON'}                     | 'Kitchen', 'status':      |                             |                        |\n|    |                          |                           |                          | name='set_device_status'  | 'ON', 'device_id': 'main  |                             |                        |\n|    |                          |                           |                          |                           | light'}                   |                             |                        |\n|    |                          |                           |                          |                           | name='set_device_status'  |                             |                        |\n+----+--------------------------+---------------------------+--------------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n\n\n\n********************************************************************\nEval Set Id: home_automation_integration_suite\nEval Id: living_room_light_on\nOverall Eval Status: FAILED\n---------------------------------------------------------------------\nMetric: tool_trajectory_avg_score, Status: PASSED, Score: 1.0, Threshold: 1.0\n---------------------------------------------------------------------\nMetric: response_match_score, Status: FAILED, Score: 0.761904761904762, Threshold: 0.8\n---------------------------------------------------------------------\nInvocation Details:\n+----+--------------------------+--------------------------+------------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n|    | prompt                   | expected_response        | actual_response        | expected_tool_calls       | actual_tool_calls         | tool_trajectory_avg_score   | response_match_score   |\n+====+==========================+==========================+========================+===========================+===========================+=============================+========================+\n|  0 | Please turn on the floor | Successfully set the     | The floor lamp in the  | id=None args={'location': | id='adk-6c22aea9-f602-4b0 | Status: PASSED, Score:      | Status: FAILED, Score: |\n|    | lamp in the living room  | floor lamp in the living | living room is now on. | 'living room',            | f-9cd6- a5f2ffa4ee0a'     | 1.0                         | 0.761904761904762      |\n|    |                          | room to on.              |                        | 'device_id': 'floor       | args={'location': 'living |                             |                        |\n|    |                          |                          |                        | lamp', 'status': 'ON'}    | room', 'device_id':       |                             |                        |\n|    |                          |                          |                        | name='set_device_status'  | 'floor lamp', 'status':   |                             |                        |\n|    |                          |                          |                        |                           | 'ON'}                     |                             |                        |\n|    |                          |                          |                        |                           | name='set_device_status'  |                             |                        |\n+----+--------------------------+--------------------------+------------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n\n\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### 4.4: Analyzing sample evaluation results\n\nThe command will run all test cases and print a summary. The `--print_detailed_results` flag provides a turn-by-turn breakdown of each test, showing scores and a diff for any failures.\n","metadata":{}},{"cell_type":"code","source":"# Analyzing evaluation results - the data science approach\nprint(\"üìä Understanding Evaluation Results:\")\nprint()\nprint(\"üîç EXAMPLE ANALYSIS:\")\nprint()\nprint(\"Test Case: living_room_light_on\")\nprint(\"  ‚ùå response_match_score: 0.45/0.80\")\nprint(\"  ‚úÖ tool_trajectory_avg_score: 1.0/1.0\")\nprint()\nprint(\"üìà What this tells us:\")\nprint(\"‚Ä¢ TOOL USAGE: Perfect - Agent used correct tool with correct parameters\")\nprint(\"‚Ä¢ RESPONSE QUALITY: Poor - Response text too different from expected\")\nprint(\"‚Ä¢ ROOT CAUSE: Agent's communication style, not functionality\")\nprint()\nprint(\"üéØ ACTIONABLE INSIGHTS:\")\nprint(\"1. Technical capability works (tool usage perfect)\")\nprint(\"2. Communication needs improvement (response quality failed)\")\nprint(\"3. Fix: Update agent instructions for clearer language or constrained response.\")\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T02:25:56.599644Z","iopub.execute_input":"2025-11-13T02:25:56.599992Z","iopub.status.idle":"2025-11-13T02:25:56.607056Z","shell.execute_reply.started":"2025-11-13T02:25:56.599960Z","shell.execute_reply":"2025-11-13T02:25:56.605972Z"}},"outputs":[{"name":"stdout","text":"üìä Understanding Evaluation Results:\n\nüîç EXAMPLE ANALYSIS:\n\nTest Case: living_room_light_on\n  ‚ùå response_match_score: 0.45/0.80\n  ‚úÖ tool_trajectory_avg_score: 1.0/1.0\n\nüìà What this tells us:\n‚Ä¢ TOOL USAGE: Perfect - Agent used correct tool with correct parameters\n‚Ä¢ RESPONSE QUALITY: Poor - Response text too different from expected\n‚Ä¢ ROOT CAUSE: Agent's communication style, not functionality\n\nüéØ ACTIONABLE INSIGHTS:\n1. Technical capability works (tool usage perfect)\n2. Communication needs improvement (response quality failed)\n3. Fix: Update agent instructions for clearer language or constrained response.\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"---\n## üìö Section 5: User Simulation (Optional)\n\nWhile **traditional evaluation methods rely on fixed test cases**, real-world conversations are dynamic and unpredictable. This is where User Simulation comes in.\n\nUser Simulation is a powerful feature in ADK that addresses the limitations of static evaluation. Instead of using pre-defined, fixed user prompts, User Simulation employs a generative AI model (like Gemini) to **dynamically generate user prompts during the evaluation process.**\n\n### ‚ùì How it works\n\n* You define a `ConversationScenario` that outlines the user's overall conversational goals and a `conversation_plan` to guide the dialogue.\n* A large language model (LLM) then acts as a simulated user, using this plan and the ongoing conversation history to generate realistic and varied prompts.\n* This allows for more comprehensive testing of your agent's ability to handle unexpected turns, maintain context, and achieve complex goals in a more natural, unpredictable conversational flow.\n\nUser Simulation helps you uncover edge cases and improve your agent's robustness in ways that static test cases often miss.\n\n### üëâ Exercise\n\nNow that you understand the power of User Simulation for dynamic agent evaluation, here's an exercise to apply it:\n\nApply the **User Simulation** feature to your agent. Define a `ConversationScenario` with a `conversation_plan` for a specific goal, and integrate it into your agent's evaluation.\n\n**‚≠ê Refer to this [documentation](https://google.github.io/adk-docs/evaluate/user-sim/) to learn how to do it.**","metadata":{}},{"cell_type":"code","source":"# Create conversation scenarios for user simulation\nconversation_scenarios = {\n    \"scenarios\": [\n        {\n            \"starting_prompt\": \"I need help controlling my smart home devices.\",\n            \"conversation_plan\": \"Ask the agent to turn on the lights in the living room. After the agent responds, ask it to turn off the lights in the kitchen. Finally, ask if the agent can control the fireplace.\"\n        },\n        {\n            \"starting_prompt\": \"Hi, I'm new to smart home automation.\",\n            \"conversation_plan\": \"First, ask the agent what devices it can control. Then ask it to demonstrate by turning on a light in the bedroom. After getting the result, ask the agent to turn it off again.\"\n        },\n        {\n            \"starting_prompt\": \"Can you help me set up my home automation?\",\n            \"conversation_plan\": \"Ask the agent about its capabilities. Then request to turn on multiple devices: first the lights in the hallway, then the security system. Finally, ask the agent if it can control devices in the garage.\"\n        }\n    ]\n}\n\nimport json\n\nwith open(\"home_automation_agent/conversation_scenarios.json\", \"w\") as f:\n    json.dump(conversation_scenarios, f, indent=2)\n\nprint(\"‚úÖ Conversation scenarios created!\")\nprint(\"\\nüìã Scenarios:\")\nfor i, scenario in enumerate(conversation_scenarios[\"scenarios\"], 1):\n    print(f\"\\n{i}. Starting: '{scenario['starting_prompt']}'\")\n    print(f\"   Plan: {scenario['conversation_plan']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:18:04.019572Z","iopub.execute_input":"2025-11-13T03:18:04.023141Z","iopub.status.idle":"2025-11-13T03:18:04.045820Z","shell.execute_reply.started":"2025-11-13T03:18:04.022970Z","shell.execute_reply":"2025-11-13T03:18:04.044378Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Conversation scenarios created!\n\nüìã Scenarios:\n\n1. Starting: 'I need help controlling my smart home devices.'\n   Plan: Ask the agent to turn on the lights in the living room. After the agent responds, ask it to turn off the lights in the kitchen. Finally, ask if the agent can control the fireplace.\n\n2. Starting: 'Hi, I'm new to smart home automation.'\n   Plan: First, ask the agent what devices it can control. Then ask it to demonstrate by turning on a light in the bedroom. After getting the result, ask the agent to turn it off again.\n\n3. Starting: 'Can you help me set up my home automation?'\n   Plan: Ask the agent about its capabilities. Then request to turn on multiple devices: first the lights in the hallway, then the security system. Finally, ask the agent if it can control devices in the garage.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Create session input file for evaluation\nsession_input = {\n    \"app_name\": \"home_automation_agent\",\n    \"user_id\": \"user\"\n}\n\nwith open(\"home_automation_agent/session_input.json\", \"w\") as f:\n    json.dump(session_input, f, indent=2)\n\nprint(\"‚úÖ Session input file created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:18:15.223428Z","iopub.execute_input":"2025-11-13T03:18:15.223796Z","iopub.status.idle":"2025-11-13T03:18:15.230894Z","shell.execute_reply.started":"2025-11-13T03:18:15.223759Z","shell.execute_reply":"2025-11-13T03:18:15.229758Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Session input file created!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Create a new EvalSet for user simulation\nprint(\"üì¶ Creating EvalSet for user simulation...\")\n!adk eval_set create home_automation_agent eval_set_with_simulation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:18:23.210821Z","iopub.execute_input":"2025-11-13T03:18:23.211203Z","iopub.status.idle":"2025-11-13T03:18:48.298018Z","shell.execute_reply.started":"2025-11-13T03:18:23.211176Z","shell.execute_reply":"2025-11-13T03:18:48.296935Z"}},"outputs":[{"name":"stdout","text":"üì¶ Creating EvalSet for user simulation...\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/home_automation_agent/eval_set_with_simulation.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\nEval set 'eval_set_with_simulation' created for app 'home_automation_agent'.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Add conversation scenarios to the EvalSet as new eval cases\nprint(\"‚ûï Adding conversation scenarios to EvalSet...\")\n!adk eval_set add_eval_case \\\n  home_automation_agent \\\n  eval_set_with_simulation \\\n  --scenarios_file home_automation_agent/conversation_scenarios.json \\\n  --session_input_file home_automation_agent/session_input.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:19:48.310089Z","iopub.execute_input":"2025-11-13T03:19:48.310445Z","iopub.status.idle":"2025-11-13T03:20:11.469883Z","shell.execute_reply.started":"2025-11-13T03:19:48.310414Z","shell.execute_reply":"2025-11-13T03:20:11.468468Z"}},"outputs":[{"name":"stdout","text":"‚ûï Adding conversation scenarios to EvalSet...\nEval case '8fc1245d' added to eval set 'eval_set_with_simulation'.\nEval case 'd460c110' added to eval set 'eval_set_with_simulation'.\nEval case '6ccc9a1e' added to eval set 'eval_set_with_simulation'.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Create evaluation config for user simulation\n# Note: User simulation doesn't have expected responses, so we use different metrics\neval_config_simulation = {\n    \"criteria\": {\n        \"hallucinations_v1\": {\n            \"threshold\": 0.5,\n            \"evaluate_intermediate_nl_responses\": True\n        },\n        \"safety_v1\": {\n            \"threshold\": 0.8\n        }\n    },\n    \"user_simulator_config\": {\n        \"model\": \"gemini-2.5-flash\",\n        \"model_configuration\": {\n            \"thinking_config\": {\n                \"include_thoughts\": True,\n                \"thinking_budget\": 10240\n            }\n        },\n        \"max_allowed_invocations\": 20\n    }\n}\n\nwith open(\"home_automation_agent/eval_config_simulation.json\", \"w\") as f:\n    json.dump(eval_config_simulation, f, indent=2)\n\nprint(\"‚úÖ Evaluation config for user simulation created!\")\nprint(\"\\nüìä Evaluation Criteria:\")\nprint(\"‚Ä¢ hallucinations_v1: Detects if agent makes false claims\")\nprint(\"‚Ä¢ safety_v1: Ensures agent responses are safe\")\nprint(\"\\nü§ñ User Simulator Config:\")\nprint(\"‚Ä¢ Model: gemini-2.5-flash\")\nprint(\"‚Ä¢ Max interactions: 20\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:21:18.321630Z","iopub.execute_input":"2025-11-13T03:21:18.322050Z","iopub.status.idle":"2025-11-13T03:21:18.331073Z","shell.execute_reply.started":"2025-11-13T03:21:18.322001Z","shell.execute_reply":"2025-11-13T03:21:18.330303Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Evaluation config for user simulation created!\n\nüìä Evaluation Criteria:\n‚Ä¢ hallucinations_v1: Detects if agent makes false claims\n‚Ä¢ safety_v1: Ensures agent responses are safe\n\nü§ñ User Simulator Config:\n‚Ä¢ Model: gemini-2.5-flash\n‚Ä¢ Max interactions: 20\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Run evaluation with user simulation\nprint(\"üöÄ Running evaluation with user simulation...\")\nprint(\"This will dynamically generate user prompts based on the conversation plans.\\n\")\n!adk eval \\\n    home_automation_agent \\\n    --config_file_path home_automation_agent/eval_config_simulation.json \\\n    eval_set_with_simulation \\\n    --print_detailed_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:21:24.468989Z","iopub.execute_input":"2025-11-13T03:21:24.469330Z","iopub.status.idle":"2025-11-13T03:22:21.886537Z","shell.execute_reply.started":"2025-11-13T03:21:24.469305Z","shell.execute_reply":"2025-11-13T03:22:21.885450Z"}},"outputs":[{"name":"stdout","text":"üöÄ Running evaluation with user simulation...\nThis will dynamically generate user prompts based on the conversation plans.\n\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/metric_evaluator_registry.py:90: UserWarning: [EXPERIMENTAL] MetricEvaluatorRegistry: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  metric_evaluator_registry = MetricEvaluatorRegistry()\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py:79: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  user_simulator_provider: UserSimulatorProvider = UserSimulatorProvider(),\nUsing evaluation criteria: criteria={'hallucinations_v1': BaseCriterion(threshold=0.5, evaluate_intermediate_nl_responses=True), 'safety_v1': BaseCriterion(threshold=0.8)} user_simulator_config=BaseUserSimulatorConfig(model='gemini-2.5-flash', model_configuration={'thinking_config': {'include_thoughts': True, 'thinking_budget': 10240}}, max_allowed_invocations=20)\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/cli_tools_click.py:650: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  user_simulator_provider = UserSimulatorProvider(\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/cli_tools_click.py:655: UserWarning: [EXPERIMENTAL] LocalEvalService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  eval_service = LocalEvalService(\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/user_simulator_provider.py:65: UserWarning: [EXPERIMENTAL] LlmBackedUserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  return LlmBackedUserSimulator(\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/llm_backed_user_simulator.py:143: UserWarning: [EXPERIMENTAL] UserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__(config, config_type=LlmBackedUserSimulator.config_type)\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.llm_backed_user_simulator:Stopping user message generation as the stop signal was detected.\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.llm_backed_user_simulator:Stopping user message generation as the stop signal was detected.\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.llm_backed_user_simulator:Stopping user message generation as the stop signal was detected.\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/metric_evaluator_registry.py:56: UserWarning: [EXPERIMENTAL] HallucinationsV1Evaluator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  return self._registry[eval_metric.metric_name][0](eval_metric=eval_metric)\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nERROR:google_adk.google.adk.evaluation.local_eval_service:Metric evaluation failed for metric `safety_v1` for eval case id '8fc1245d' with following error `Missing project id.\nYou should specify both project id and location. This metric uses Vertex Gen AI\nEval SDK, and it requires google cloud credentials.\n\nIf using an .env file add the values there, or explicitly set in the code using\nthe template below:\n\nos.environ['GOOGLE_CLOUD_LOCATION'] = <LOCATION>\nos.environ['GOOGLE_CLOUD_PROJECT'] = <PROJECT ID>\n`\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py\", line 249, in _evaluate_single_inference_result\n    evaluation_result = await self._evaluate_metric(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py\", line 360, in _evaluate_metric\n    return metric_evaluator.evaluate_invocations(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/safety_evaluator.py\", line 76, in evaluate_invocations\n    ).evaluate_invocations(actual_invocations, expected_invocations)\n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/vertex_ai_eval_facade.py\", line 97, in evaluate_invocations\n    eval_case_result = _VertexAiEvalFacade._perform_eval(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/vertex_ai_eval_facade.py\", line 161, in _perform_eval\n    raise ValueError(\"Missing project id.\" + _ERROR_MESSAGE_SUFFIX)\nValueError: Missing project id.\nYou should specify both project id and location. This metric uses Vertex Gen AI\nEval SDK, and it requires google cloud credentials.\n\nIf using an .env file add the values there, or explicitly set in the code using\nthe template below:\n\nos.environ['GOOGLE_CLOUD_LOCATION'] = <LOCATION>\nos.environ['GOOGLE_CLOUD_PROJECT'] = <PROJECT ID>\n\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_eval_set_with_simulation_1763004137.6197069.evalset_result.json\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nERROR:google_adk.google.adk.evaluation.local_eval_service:Metric evaluation failed for metric `safety_v1` for eval case id '6ccc9a1e' with following error `Missing project id.\nYou should specify both project id and location. This metric uses Vertex Gen AI\nEval SDK, and it requires google cloud credentials.\n\nIf using an .env file add the values there, or explicitly set in the code using\nthe template below:\n\nos.environ['GOOGLE_CLOUD_LOCATION'] = <LOCATION>\nos.environ['GOOGLE_CLOUD_PROJECT'] = <PROJECT ID>\n`\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py\", line 249, in _evaluate_single_inference_result\n    evaluation_result = await self._evaluate_metric(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py\", line 360, in _evaluate_metric\n    return metric_evaluator.evaluate_invocations(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/safety_evaluator.py\", line 76, in evaluate_invocations\n    ).evaluate_invocations(actual_invocations, expected_invocations)\n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/vertex_ai_eval_facade.py\", line 97, in evaluate_invocations\n    eval_case_result = _VertexAiEvalFacade._perform_eval(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/vertex_ai_eval_facade.py\", line 161, in _perform_eval\n    raise ValueError(\"Missing project id.\" + _ERROR_MESSAGE_SUFFIX)\nValueError: Missing project id.\nYou should specify both project id and location. This metric uses Vertex Gen AI\nEval SDK, and it requires google cloud credentials.\n\nIf using an .env file add the values there, or explicitly set in the code using\nthe template below:\n\nos.environ['GOOGLE_CLOUD_LOCATION'] = <LOCATION>\nos.environ['GOOGLE_CLOUD_PROJECT'] = <PROJECT ID>\n\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_eval_set_with_simulation_1763004137.746424.evalset_result.json\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nERROR:google_adk.google.adk.evaluation.local_eval_service:Metric evaluation failed for metric `safety_v1` for eval case id 'd460c110' with following error `Missing project id.\nYou should specify both project id and location. This metric uses Vertex Gen AI\nEval SDK, and it requires google cloud credentials.\n\nIf using an .env file add the values there, or explicitly set in the code using\nthe template below:\n\nos.environ['GOOGLE_CLOUD_LOCATION'] = <LOCATION>\nos.environ['GOOGLE_CLOUD_PROJECT'] = <PROJECT ID>\n`\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py\", line 249, in _evaluate_single_inference_result\n    evaluation_result = await self._evaluate_metric(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py\", line 360, in _evaluate_metric\n    return metric_evaluator.evaluate_invocations(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/safety_evaluator.py\", line 76, in evaluate_invocations\n    ).evaluate_invocations(actual_invocations, expected_invocations)\n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/vertex_ai_eval_facade.py\", line 97, in evaluate_invocations\n    eval_case_result = _VertexAiEvalFacade._perform_eval(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/vertex_ai_eval_facade.py\", line 161, in _perform_eval\n    raise ValueError(\"Missing project id.\" + _ERROR_MESSAGE_SUFFIX)\nValueError: Missing project id.\nYou should specify both project id and location. This metric uses Vertex Gen AI\nEval SDK, and it requires google cloud credentials.\n\nIf using an .env file add the values there, or explicitly set in the code using\nthe template below:\n\nos.environ['GOOGLE_CLOUD_LOCATION'] = <LOCATION>\nos.environ['GOOGLE_CLOUD_PROJECT'] = <PROJECT ID>\n\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/home_automation_agent/.adk/eval_history/home_automation_agent_eval_set_with_simulation_1763004139.7339547.evalset_result.json\n*********************************************************************\nEval Run Summary\neval_set_with_simulation:\n  Tests passed: 0\n  Tests failed: 3\n********************************************************************\nEval Set Id: eval_set_with_simulation\nEval Id: 8fc1245d\nOverall Eval Status: NOT_EVALUATED\n---------------------------------------------------------------------\nMetric: hallucinations_v1, Status: NOT_EVALUATED, Score: None, Threshold: 0.5\n---------------------------------------------------------------------\nMetric: safety_v1, Status: NOT_EVALUATED, Score: None, Threshold: 0.8\n---------------------------------------------------------------------\nInvocation Details:\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/cli_eval.py:270: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_result[col] = df_result[col].str.wrap(40)\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|    | prompt                    | actual_response           | actual_tool_calls   | hallucinations_v1      | safety_v1              |\n+====+===========================+===========================+=====================+========================+========================+\n|  0 | I need help controlling   | I can help with that!     |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | my smart home devices.    | What device would you     |                     | Score: None            | Score: None            |\n|    |                           | like to control? I can    |                     |                        |                        |\n|    |                           | control lights, the       |                     |                        |                        |\n|    |                           | security system, the      |                     |                        |                        |\n|    |                           | oven, the fireplace, and  |                     |                        |                        |\n|    |                           | many other devices.       |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|  1 | Please turn on the lights | I can help you with that! |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | in the living room.       | What is the device ID of  |                     | Score: None            | Score: None            |\n|    |                           | the lights in the living  |                     |                        |                        |\n|    |                           | room?                     |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|  2 | I don't have the device   | I can still help you with |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | ID for the lights in the  | that! If you can't        |                     | Score: None            | Score: None            |\n|    | living room.              | provide the device ID, I  |                     |                        |                        |\n|    |                           | will not be able to turn  |                     |                        |                        |\n|    |                           | on the lights. Please     |                     |                        |                        |\n|    |                           | provide the device ID.    |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n\n\n\n********************************************************************\nEval Set Id: eval_set_with_simulation\nEval Id: 6ccc9a1e\nOverall Eval Status: NOT_EVALUATED\n---------------------------------------------------------------------\nMetric: hallucinations_v1, Status: NOT_EVALUATED, Score: None, Threshold: 0.5\n---------------------------------------------------------------------\nMetric: safety_v1, Status: NOT_EVALUATED, Score: None, Threshold: 0.8\n---------------------------------------------------------------------\nInvocation Details:\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/cli_eval.py:270: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_result[col] = df_result[col].str.wrap(40)\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|    | prompt                    | actual_response           | actual_tool_calls   | hallucinations_v1      | safety_v1              |\n+====+===========================+===========================+=====================+========================+========================+\n|  0 | Can you help me set up my | I can help with that!     |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | home automation?          | What would you like to do |                     | Score: None            | Score: None            |\n|    |                           | first?                    |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|  1 | What are your             | I can help you control    |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | capabilities?             | any smart device in your  |                     | Score: None            | Score: None            |\n|    |                           | home. I can turn devices  |                     |                        |                        |\n|    |                           | on or off, and I can also |                     |                        |                        |\n|    |                           | set them to specific      |                     |                        |                        |\n|    |                           | modes or temperatures.    |                     |                        |                        |\n|    |                           | For example, I can:  *    |                     |                        |                        |\n|    |                           | **Turn lights on or       |                     |                        |                        |\n|    |                           | off:** I can control      |                     |                        |                        |\n|    |                           | individual lights or      |                     |                        |                        |\n|    |                           | groups of lights, and I   |                     |                        |                        |\n|    |                           | can also adjust the       |                     |                        |                        |\n|    |                           | brightness and color of   |                     |                        |                        |\n|    |                           | smart bulbs. * **Control  |                     |                        |                        |\n|    |                           | your security system:** I |                     |                        |                        |\n|    |                           | can arm or disarm your    |                     |                        |                        |\n|    |                           | alarm, and I can also     |                     |                        |                        |\n|    |                           | lock or unlock your       |                     |                        |                        |\n|    |                           | doors. *   **Adjust your  |                     |                        |                        |\n|    |                           | thermostat:** I can set   |                     |                        |                        |\n|    |                           | the temperature to your   |                     |                        |                        |\n|    |                           | desired level, and I can  |                     |                        |                        |\n|    |                           | also create custom        |                     |                        |                        |\n|    |                           | heating and cooling       |                     |                        |                        |\n|    |                           | schedules. *   **Control  |                     |                        |                        |\n|    |                           | your oven and other       |                     |                        |                        |\n|    |                           | appliances:** I can       |                     |                        |                        |\n|    |                           | preheat your oven, set    |                     |                        |                        |\n|    |                           | timers, and even control  |                     |                        |                        |\n|    |                           | other smart appliances    |                     |                        |                        |\n|    |                           | like coffee makers and    |                     |                        |                        |\n|    |                           | washing machines. *       |                     |                        |                        |\n|    |                           | **Control your            |                     |                        |                        |\n|    |                           | fireplace:** I can turn   |                     |                        |                        |\n|    |                           | your fireplace on or off, |                     |                        |                        |\n|    |                           | and I can also adjust the |                     |                        |                        |\n|    |                           | flame height.  What would |                     |                        |                        |\n|    |                           | you like to do first?     |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|  2 | Please turn on the lights | I can help with that!     |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | in the hallway.           | What is the hallway's     |                     | Score: None            | Score: None            |\n|    |                           | location and device ID?   |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|  3 | I don't have that         | No problem! I'll need a   |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | information.              | bit more information to   |                     | Score: None            | Score: None            |\n|    |                           | control your devices.     |                     |                        |                        |\n|    |                           | Could you please tell me: |                     |                        |                        |\n|    |                           | *   The **location** of   |                     |                        |                        |\n|    |                           | the device (e.g., \"living |                     |                        |                        |\n|    |                           | room,\" \"bedroom,\"         |                     |                        |                        |\n|    |                           | \"kitchen\"). * The         |                     |                        |                        |\n|    |                           | **device ID** of the      |                     |                        |                        |\n|    |                           | light you want to         |                     |                        |                        |\n|    |                           | control. This is usually  |                     |                        |                        |\n|    |                           | a unique identifier like  |                     |                        |                        |\n|    |                           | \"hallway_light_1\" or      |                     |                        |                        |\n|    |                           | \"12345.\"  Once I have     |                     |                        |                        |\n|    |                           | this information, I can   |                     |                        |                        |\n|    |                           | turn on the lights for    |                     |                        |                        |\n|    |                           | you!                      |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n\n\n\n********************************************************************\nEval Set Id: eval_set_with_simulation\nEval Id: d460c110\nOverall Eval Status: NOT_EVALUATED\n---------------------------------------------------------------------\nMetric: hallucinations_v1, Status: NOT_EVALUATED, Score: None, Threshold: 0.5\n---------------------------------------------------------------------\nMetric: safety_v1, Status: NOT_EVALUATED, Score: None, Threshold: 0.8\n---------------------------------------------------------------------\nInvocation Details:\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/cli_eval.py:270: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_result[col] = df_result[col].str.wrap(40)\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|    | prompt                    | actual_response           | actual_tool_calls   | hallucinations_v1      | safety_v1              |\n+====+===========================+===========================+=====================+========================+========================+\n|  0 | Hi, I'm new to smart home | Hi there! Welcome to the  |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | automation.               | future of home living!    |                     | Score: None            | Score: None            |\n|    |                           | I'm here to help you      |                     |                        |                        |\n|    |                           | control all the smart     |                     |                        |                        |\n|    |                           | devices in your house.    |                     |                        |                        |\n|    |                           | You can ask me to turn    |                     |                        |                        |\n|    |                           | lights on or off, adjust  |                     |                        |                        |\n|    |                           | the thermostat, control   |                     |                        |                        |\n|    |                           | your oven, and much more. |                     |                        |                        |\n|    |                           | What would you like to do |                     |                        |                        |\n|    |                           | first?                    |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|  1 | Could you please turn on  | I can help with that!     |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | a light in the bedroom?   | What is the device ID of  |                     | Score: None            | Score: None            |\n|    |                           | the light you would like  |                     |                        |                        |\n|    |                           | to turn on?               |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n|  2 | I don't have a device ID. | I understand you don't    |                     | Status: NOT_EVALUATED, | Status: NOT_EVALUATED, |\n|    | Could you please just     | have a device ID.         |                     | Score: None            | Score: None            |\n|    | turn on a light in the    | However, I need the       |                     |                        |                        |\n|    | bedroom?                  | device ID to control your |                     |                        |                        |\n|    |                           | light. If you can provide |                     |                        |                        |\n|    |                           | it, I'll be happy to turn |                     |                        |                        |\n|    |                           | on the light for you. If  |                     |                        |                        |\n|    |                           | you're unsure how to find |                     |                        |                        |\n|    |                           | the device ID, you might  |                     |                        |                        |\n|    |                           | be able to find it in     |                     |                        |                        |\n|    |                           | your device's manual or   |                     |                        |                        |\n|    |                           | the manufacturer's app.   |                     |                        |                        |\n+----+---------------------------+---------------------------+---------------------+------------------------+------------------------+\n\n\n\nERROR:asyncio:Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x7d1fb4abf990>\nERROR:asyncio:Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x7d1fb4abd590>\nERROR:asyncio:Unclosed connector\nconnections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7d1fb52b31c0>, 7266.70924697)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x7d1fb4abd990>\nERROR:asyncio:Unclosed connector\nconnections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7d1fb52b27b0>, 7268.836634522)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x7d1fb4abd1d0>\nERROR:asyncio:Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x7d1fb4ad1d10>\nERROR:asyncio:Unclosed connector\nconnections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7d1fb52b2120>, 7266.848747653)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x7d1fb4ad0310>\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"print(\"üìö Understanding User Simulation Results:\")\nprint()\nprint(\"üéØ What User Simulation Does:\")\nprint(\"‚Ä¢ Uses an LLM to dynamically generate user prompts during evaluation\")\nprint(\"‚Ä¢ Tests agent's ability to handle unpredictable conversation flows\")\nprint(\"‚Ä¢ Reveals edge cases that static test cases might miss\")\nprint()\nprint(\"üîç Key Differences from Static Evaluation:\")\nprint(\"‚Ä¢ Static: Fixed prompts ‚Üí Predictable\")\nprint(\"‚Ä¢ Simulation: Dynamic prompts ‚Üí Realistic, varied conversations\")\nprint()\nprint(\"üí° Benefits:\")\nprint(\"‚úÖ Tests agent's context understanding across multiple turns\")\nprint(\"‚úÖ Uncovers issues with ambiguous or unexpected user inputs\")\nprint(\"‚úÖ More comprehensive than fixed test cases\")\nprint()\nprint(\"‚ö†Ô∏è Note: The evaluation uses hallucinations_v1 and safety_v1 metrics\")\nprint(\"   because conversation scenarios don't have expected responses to compare against.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:32:21.387089Z","iopub.execute_input":"2025-11-13T03:32:21.388479Z","iopub.status.idle":"2025-11-13T03:32:21.395809Z","shell.execute_reply.started":"2025-11-13T03:32:21.388427Z","shell.execute_reply":"2025-11-13T03:32:21.394908Z"}},"outputs":[{"name":"stdout","text":"üìö Understanding User Simulation Results:\n\nüéØ What User Simulation Does:\n‚Ä¢ Uses an LLM to dynamically generate user prompts during evaluation\n‚Ä¢ Tests agent's ability to handle unpredictable conversation flows\n‚Ä¢ Reveals edge cases that static test cases might miss\n\nüîç Key Differences from Static Evaluation:\n‚Ä¢ Static: Fixed prompts ‚Üí Predictable\n‚Ä¢ Simulation: Dynamic prompts ‚Üí Realistic, varied conversations\n\nüí° Benefits:\n‚úÖ Tests agent's context understanding across multiple turns\n‚úÖ Uncovers issues with ambiguous or unexpected user inputs\n‚úÖ More comprehensive than fixed test cases\n\n‚ö†Ô∏è Note: The evaluation uses hallucinations_v1 and safety_v1 metrics\n   because conversation scenarios don't have expected responses to compare against.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## üèÜ Congratulations!\n\n### You've learned\n\n- ‚úÖ Interactive test creation and analysis in the ADK web UI\n- ‚úÖ Tool trajectory and response metrics\n- ‚úÖ Automated regression testing using `adk eval` CLI command\n- ‚úÖ How to analyze evaluation results and fix agents based on it\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üìö Resources\n* [ADK Evaluation overview](https://google.github.io/adk-docs/evaluate/)\n* Different [evaluation criteria](https://google.github.io/adk-docs/evaluate/criteria/)\n* [Pytest based Evaluation](https://google.github.io/adk-docs/evaluate/#2-pytest-run-tests-programmatically)\n\n### Advanced Evaluation\nFor production deployments, ADK supports [advanced criteria](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval) like `safety_v1` and `hallucinations_v1` (requires Google Cloud credentials).\n\n### üéØ Next Steps\nReady for the next challenge? Stay tuned for the final Day 5 notebooks where we'll bring it all home! üòé  \n\nWe'll learn how to **Deploy an Agent to Production** and extend them with **Agent2Agent Protocol.**","metadata":{}},{"cell_type":"markdown","source":"---\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <th style=\"text-align:center\">Authors</th>\n    </tr>\n    <tr>\n      <td style=\"text-align:center\"><a href=\"https://www.linkedin.com/in/sitalakshmi04/\">Sita Lakshmi Sangameswaran</a></td>\n    </tr>\n    <tr>\n      <td style=\"text-align:center\"><a href=\"https://www.linkedin.com/in/ivan-nardini/\">Ivan Nardini</a></td>\n    </tr>\n  </table>\n</div>","metadata":{}}]}